<!DOCTYPE html>
<html lang="en">
  <head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    
    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/bootstrap-responsive.min.css" rel="stylesheet">
    <link href="css/starter-template.css" rel="stylesheet">
        
    <link href="css/main.css" rel="stylesheet">
    
        <title>CS699: Trustworthy ML</title>
  </head>

<body>
<div class="container">

            <div class="row">
            <div class="col-lg-12">
                <h1 class="page-header" style="color:#B03A2E;">CSCI 699: Trustworthy Machine Learning from an Optimization Lens
                </h1>
            </div>
        </div>

<p>

<h3 style="color:#1F618D;">Instructors: Meisam Razaviyayn, Vatsal Sharan </h3>




<h3 style="color:#1F618D;">Basic Information</h3>

<ul>
    <li> <b> Lecture time: </b> Wednesday 4:00 pm to 7:20 pm
    <li> <b> Lecture place: </b> THH B9
            <li> <b>TAs: </b> TBD
            <li> <b>CP & Grader: </b>
                TBD
                    <li> <b> Communication: </b> We will primarily use Slack for communication. 
                <li> <b> Gradescope: </b> We will use <a href="https://gradescope.com/">Gradescope </a> for assignment and final project submission.
    </ul>
        

<h3 style="color:#1F618D;">Course Description and Objectives</h3>

Optimization techniques lie at the heart of how models are trained and developed. In this course, we will explore modern considerations such as privacy, robustness and fairness, particularly from the standpoint of optimization techniques. We will both discuss recent research work on formalizing these societal requirements, and algorithmic solutions for obtaining them. Optimization-based approaches such as differentially private optimization, minimax and constrained optimization are particularly useful toolboxes for these problems, and will be explored in this context.

<h3 style="color:#1F618D;">Recommended Preparation</h3>

Machine learning knowledge (at the level of CSCI 567, CSCI 467, or ISE 529 is sufficient) using Python. Basic
optimization knowledge, basic probability and linear algebra concepts. Mathematical maturity to read research papers. 

           
<h3 style="color:#1F618D;">Syllabus and Materials</h3>

The following is a tentative schedule. We will post lecture notes and assignments here. Additional related reading for all lectures will be posted on ed discussion after the lecture.
<br><br>
<div id="table-custom">
    <table style="width:100%" align="right">
        <tr>
            <th style="text-align:center; width:8%;">Lecture</th>
            <th style="text-align:center">Topics</th>
            <th style="text-align:center">Lecture notes</th>
            <th style="text-align:center; width:11%;">Homework</th>
        </tr>
<tr>
  <td align="center">1, 08/27</td>
  <td align="left"> Course introduction, ML basics, Adversarial examples, Data poisoning 


  </td>
  <td align="center">
        
  </td>
  <td align="center"></td>
</tr>

<tr>
  <td align="center">2, 09/03</td>
  <td align="left"> Adversarial training, Certified robustness <br>
Paper presentations: <br>
(1) <a href="https://arxiv.org/pdf/1911.05911.pdf">Recent Advances in Algorithmic High-Dimensional Robust Statistics</a> (also see <a href="http://people.csail.mit.edu/moitra/docs/cacmrobust.pdf">Robustness Meets Algorithms </a>) <br>
(2) <a href="https://arxiv.org/pdf/2310.08419">Jailbreaking Black Box Large Language Models in Twenty Queries </a>

  </td>
  <td align="center">
      
  </td>
  <td align="center">
      
  </td>
</tr>
<tr>
  <td align="center">3, 09/10</td>
  <td align="left"> Distributional robustness <br>
Paper presentations: <br>
(1) <a href="https://arxiv.org/pdf/2412.16339.pdf">Deliberative Alignment: Reasoning Enables Safer Language Models </a>(try to brielfy cover <a href="https://arxiv.org/pdf/2502.01633.pdf">Adversarial Reasoning at Jailbreaking Time</a>) <br>
(2) <a href="https://dl.acm.org/doi/pdf/10.1145/3717823.3718245">Oblivious Defense in ML Models: Backdoor Removal without Detection</a> <br>
(3) <a href="https://proceedings.mlr.press/v97/recht19a/recht19a.pdf">Do ImageNet Classifiers Generalize to ImageNet?</a><br>
(4) <a href="https://arxiv.org/abs/2107.04649">Accuracy on the Line: On the Strong Correlation Between Out-of-Distribution and In-Distribution Generalization </a> (try to briefly cover <a href="https://arxiv.org/abs/2406.19049">Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation</a>)
  </td>
  <td align="center">
      
  </td>
  <td align="center">
      <!-- <a href="/lecture_notes/hw1.pdf">HW1</a></td>-->
</tr>

<tr>
  <td align="center">4, 09/17</td>
  <td align="left"> Fairness notions in classification, inherent tradeoffs between notions
  </td>
  <td align="center">
      
  </td>
  <td align="center"></td>
</tr>

<tr>
  <td align="center">5, 09/24</td>
  <td align="left"> Individual fairness, group fairness
  </td>
  <td align="center">
      
  </td>
  <td align="center"></td>
</tr>

<tr>
  <td align="center">6, 10/01</td>
  <td align="left"> Calibration, multicalibration, conformal prediction
  </td>
  <td align="center">
      
  </td>
  <td align="center">
      
  </td>
</tr>
<tr>
  <td align="center">7, 10/08</td>
  <td align="left"> Review of iteration complexity analysis: smooth convex, strongly convex, and nonconvex
  </td>
      <td align="center">
          
      </td>
      <td align="center"></td>
    </tr>


  <td align="center">8, 10/15</td>
  <td align="left"> Privacy and membership inference attacks
  </td>
  <td align="center">
      
  </td>
  <td align="center"></td>
</tr>

<tr>
  <td align="center">9, 10/22</td>
  <td align="left"> Differential privacy and its basic properties
  </td>
  <td align="center">
      
  </td>
  <td align="center"></td>
</tr>

<tr>
  <td align="center">10, 10/29</td>
  <td align="left"> DP mechanisms and properties of DP
  </td>
      <td align="center">
          
      </td>
      <td align="center">
    </tr>

<tr>
  <td align="center">11, 11/05</td>
  <td align="left"> DP optimization: output perturbation, objective perturbation, and exponential mechanism
  </td>
  <td align="center">
   
  </td>
  <td align="center">
  </td>
</tr>
<tr>
  <td align="center">12, 11/12</td>
  <td align="left"> DP optimization: DP-SGD and its variants
  </td>
  <td align="center"></td>
  <td align="center"></td>
</tr>

<tr>
  <td align="center">13, 11/19</td>
  <td align="left">Project presentations
  </td>
  <td align="center"></td>
  <td align="center"></td>
</tr>

<tr>
  <td align="center">14, 12/03</td>
  <td align="left">AI Safety, Alignment
  </td>
  <td align="center"></td>
  <td align="center"></td>
</tr>
</table>
</div>
     
<div><h3 style="color:#1F618D;">Requirements and Grading</h3></div>

<ol>
    
    <li>  <b> 2 homeworks </b> worth 15% of the grade. Discussion is allowed and encouraged but everyone should write solutions on their own. Homeworks should be written in Latex and submitted via Gradescope.

    <li> <b> Mini-homeworks </b> worth 15% of the grade. You should read presented papers before class so that you can contribute and get the most out of the presentation and discussion. Part of the course grade is also based on this via mini-homeworks. For every lecture day, you can fill out <a href=https://forms.gle/eMoRqycqsyUM9cDi7>this form</a> before 10 am on that day. More instructions are given on the form. We will drop your lowest mini-homework score for the final grade.

    <li> Each student will be required to <b> present a paper </b> in class, which will be worth 15% of the grade.
        
        <li> The research components will be a <b> project proposal </b> (5%), a <b> project presentation </b> (15%), and a <b> project final report </b> (25%). An overview of the requirements is given below, detailed instructions will be discussed later. The project will be in <b>groups of two students. </b>
            
            <ul> <li> The goal of the project is to give you experience in research on topics in trustworthy ML. You are free to pursue a purely theoretical project, a purely empirical project, or some combination of these. You can discuss project ideas with the instructors.
                 <li> The project proposal is meant to finalize your project topic, and will be a short 1 page report.
                 <li> The project presentations will be held in class on 11/19. Your project need not be complete by this stage, but you should have made reasonable progress.
                 <li> The project final report has to be written in Latex and should be 8-9 pages long, excluding references. Part of the report should  discuss the related research landscape, and the rest of it should cover your original work. Please use the LaTex template based on the NeurIPS format. The project should be written in a way such that most students in the class should be able to understand the report. 
                 <li> You are free to use LLMs/generative AI tools to help you with your research, but must disclose how LLMs were used in your project report (not part of the page limit). Students still bear full responsibility for the contents of the report, including content generated by LLMs that could be construed as plagiarism or scientific misconduct (e.g., fabrication of facts). 
                     </ul> 
                     <li> 5% of the grade will be based on <b> scribing</b> a lecture.
            <li> 5% of the grade will be based on <b> course attendance and participation</b>.
</ol>

<h3 style="color:#1F618D;">Resources and related courses</h3>

     
      <br><br><br>
     
</div>
</div>
</body>
</html>

